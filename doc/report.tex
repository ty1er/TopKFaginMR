\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{amsmath}
\usepackage{float}
\usepackage{listings}
\usepackage{color}
%configuring listing properties
\lstset{ 
language=java, 
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
numbers=none,                   % where to put the line-numbers
xleftmargin=2em,
numberstyle=\footnotesize,      % the size of the fonts that are used for the line-numbers
stepnumber=2,                   % the step between two line-numbers. If it's 1, each line will be numbered
numbersep=5pt,                  % how far the line-numbers are from the code
backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=yes,                   % adds a frame around the code
tabsize=2,                      % sets default tabsize to 2 spaces
captionpos=b,                   % sets the caption-position to bottom
breaklines=true,                % sets automatic line breaking
breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
escapeinside={(*}{*)},         % if you want to add a comment within your code
morekeywords={*,...},            % if you want to add more keywords to the set
keywordstyle=\color[rgb]{0,0,1},
commentstyle=\color[rgb]{0.133,0.545,0.133},
stringstyle=\color[rgb]{0.627,0.126,0.941},
keepspaces=true
}

\setlength{\textheight}{730pt}
\setlength{\topmargin}{-0.3in}
\setlength{\headsep}{0pt}
\setlength{\oddsidemargin}{-6mm}
\setlength{\textwidth}{7in}

\title{CS 236: MapReduce Project}
\author{Ildar Absalyamov \and Longxiang Chen}

\begin{document}

\maketitle

\section{Description}

Our goal for this project was to implement Fagin Algorithm for searching top-k element in dataset on distributed MapReduce environment.
We used Hadoop as a MapReduce framework, therefore all source code is written in Java.

The rest of the report is organized as follows: Section \ref{sec:preprocess} is describing initial datasets preprocessing approach, Section \ref{sec:iterative} presents na\"{\i}ve implementation of Fagin algorithm using Hadoop, Section \ref{sec:mapreduce} provides detail description of our MapReduce approach, Section \ref{sec:experiments} shows experimental results.

\section{Preprocessing}
\label{sec:preprocess}

Since the initial datasets are unordered and have different attribute ranges we need to do initial data preprocessing in order to start Fagin algorithm.
Preprocessing step could be done in a different way, as opposed to the target algorithm (i.e. running special script on dataset file), but this limits program's portability and brings additional steps to run it, therefore we implemented preprocessing step also as a MapReduce job, which prepares data for subsequent jobs (since their execution is chained).
Results presented in Section \ref{sec:experiments} do not include execution time of this step.

Dataset preprocessing could be divided into several parts:
\begin{enumerate}
	\item Attribute range normalization.

		Attribute values from dataset1 lie in range [-1;1], which is not appropriate range for calculating object score, because our score function is additive and adding attributes which have values less then 0 do not maintain monotonic increase property.
		
		In order to normalize attribute values we just add 1 to every item.
		This will result in attribute values having range [0;2], which satisfies monotonic condition, however we need to take into account this fact when we will calculate final score for top-k objects and subtract extra 1's from this result. The value that we should add (which is 1) differs for various datasets (dataset2 doesn't need normalization at all), therefore it is passed as an optional runtime parameter, which default value is 0.  
		Normalization is done in map phase of rank soring preprocess step.
	\item Attribute filtering.

		Since our score function looks like this $f(t) = sum( t.attr1, t.attr2, t.attr7, t.attr8, t.attr9)$ and does not include every object's attribute we need to filter them out.

		Filtering is done in rank soring map phase as well.
 	\item Attribute rank sorting.

 		For Fagin algorithm objects need to be sorted in decreasing order of their attribute values separately for each individual attribute.

 		This sorting is done as a distinct MapReudce job. 
 		In a map phase we are extracting objects along with their property values and emitting pairs \{propId:value,objectId:value\}:    
 		\lstinputlisting[language=java,linerange={55-56,58-58,60-60}]{../src/main/java/edu/ucr/cs236/RankSorting.java}
 		
 		The reason why we duplicate attribute value in key is the following: Hadoop is capable of sorting key-value pairs in reducer, but this sorting could be applied only to key. By duplicating value in key we are allowing these pairs to be sorted during shuffle phase before they are passed to reducer:
		\lstinputlisting[language=java,linerange={96-97,99-102}]{../src/main/java/edu/ucr/cs236/RankSorting.java}
 		
 		However by default MapReduce framework will call reducer for each different key (which is propId:value). In order to redirect pairs with the same propId to one reducer we implement custom partitioner:
 		\lstinputlisting[language=java,linerange={129-130}]{../src/main/java/edu/ucr/cs236/RankSorting.java}

 		Reduce phase is simply writing already sorted results with the appropriate line number (we will use this line number later): 
 		\lstinputlisting[language=java,linerange={74-78}]{../src/main/java/edu/ucr/cs236/RankSorting.java}
\end{enumerate}

\section{Iterative algorithm}
\label{sec:iterative}

The very first version we devised was implementing iterative approach (reading input line by line and maintaining lists of objects seen so far and objects appeared in every list) of the original Fagin algorithm on Hadoop.
This was a straightforward implementation in terms of algorithm modification, however we faced several problems while doing this:
\begin{enumerate}
    \item If we want to implement each iteration as distinct MapReduce job we need to came up with the input and output file format.
    These formats should be the same, because output of $i^{th}$ iteration is an input of $i+1^{th}$, which is not trivial thing to do.
    \item Even after resolving file format issue we encountered another problem: in iterative approach each iteration need to do IO operations, reading it's input from HDFS and writing it's result back to disk.
    With the large datasets this becomes a major issue, which could be addressed only by changing Hadoop algorithm.
\end{enumerate}

With all these problems we realized that we need to make a number of improvements to the original algorithm in order to execute it on Hadoop in effective manner.
Special attention should be paid to IO, since it is the limiting factor for MapReduce tasks. 

\section{MapReduce implementation}
\label{sec:mapreduce}

Proposed implementation uses several chained MapReduce jobs, which introduces some overhead due to IO needed to intermediate results, however complexity of this overhead is constant, unlike the iterative approach, which is $O(n)$ algorithm.

Let's describe each particular node in job chain:
\begin{enumerate}
    \item Object occurrence range extracting. \label{enum:objOccurrence}

    This step extracts the line number of first and last occurrence of every object in dataset.
    Input is initial sorted dataset (including line numbers)
    Map phase just emits \{key, value\} pair of objectId and lineNum when it was occurred:
    \lstinputlisting[language=java,linerange={42-43}]{../src/main/java/edu/ucr/cs236/ObjectOccurrence.java}

    Since shuffle will put line numbers for each object in distinct reduce calls all we need to do in reduce phase is peak minimum and maximum among them: 
    \lstinputlisting[language=java,linerange={52-60}]{../src/main/java/edu/ucr/cs236/ObjectOccurrence.java}

    \item End Sorting.
    \label{enum:endSort}

    Input for this job is the output of the job \ref{enum:objOccurrence}.

    This job discovers what should be the last line up until which we should read original input in order to select top-k objects.
    This is done by sorting the input according to last occurrence line number.
    
    During map phase we just emit last occurrence as a key of \{key, value\} in order to perform sorting against it:
    \lstinputlisting[language=java,linerange={48-48}]{../src/main/java/edu/ucr/cs236/EndSorting.java}

    The main work is done in reducer: first we need to discover what is $k^{th}$ object last occurrence time, which corresponds to the line number when we would have k objects for which we have seen all attributes.
    We will call last occurrence lastcheck.

    Then we keep traversing the sorted list up until the end and if first occurrence of an object is less then lastcheck we are recording it's last occurrence.
    This corresponds to situation when we add this object to the list of objects seen so far in original Fagin algorithm.
    Since values are sorted against the last occurrence in increasing order the last record where $first occurrence < lastcheck$ has the greatest last occurrence, therefore we will not miss anything:
    \lstinputlisting[language=java,linerange={60-71}]{../src/main/java/edu/ucr/cs236/EndSorting.java}

    The obtained value would we passed to subsequent jobs though MapReduce counter.

    \item Object score calculation.
    \label{enum:scoreCalc}

    During this step we will read original algorithm input again in order to calculate object scores, but this time we will read only only first N lines of the file. 
    The value of N was discovered during job \ref{enum:endSort}.

    Implementation is very simple, in mapper we just extract attribute value and emit \{objectId,value\} pair:
    \lstinputlisting[language=java,linerange={45-49}]{../src/main/java/edu/ucr/cs236/ScoreCalculation.java}

    Reducer just sums up these values to obtain object score:
    \lstinputlisting[language=java,linerange={58-62}]{../src/main/java/edu/ucr/cs236/ScoreCalculation.java}

    \item Top-k filtering.

    This is a final step, which filters first k objects from output obtained on previous step.
    Hence the input is the output of job \ref{enum:scoreCalc}.

    To perform filtering we need sort objects according their score.
    This sorting is similar to sorting in preprocessing stage.
    First we need to emit score as a key, therefore we just swap objectId and it's score (objectId in new value) in mapper:
    \lstinputlisting[language=java,linerange={47-47}]{../src/main/java/edu/ucr/cs236/TopKFilter.java}

    To sort object in decreasing scores order we implement custom comparator:
    \lstinputlisting[language=java,linerange={71-71}]{../src/main/java/edu/ucr/cs236/TopKFilter.java}

    During reduce phase just we need to output first k value as an algorithm output:
    \lstinputlisting[language=java,linerange={54-60}]{../src/main/java/edu/ucr/cs236/TopKFilter.java}
\end{enumerate}

\section{Experimental evaluation}
\label{sec:experiments}

The experimental results for dataset1 and dataset2 are provided in Tables \ref{tab:dataset1} and \ref{tab:dataset2} respectively. 

Preprocessing step (RankSorting) is not a part added to total execution time.

The results does not show any performance gain when we are increasing number of mappers or reducers.
This could be explained by the number of facts:
\begin{enumerate}
    \item We were running Hadoop in pseudo-distributed mode (everything on 1 node) so we could not obtain high speedup due to parallelization.
    \item Our Hadoop pseudo-cluster was running on Virtual Machine, which has by default limited number of available resources.
    \item We manually specified number of mappers/reducers only for the first/last MapReduce job in our chain. We did not change configuration for jobs in between, because it substantially increase the number of possible configurations
    \item The size of datasets which we have used is not typical for tasks, solved by MapReduce. Because MapReduce has pretty high startup overhead the scalability could be observed only on dataset which are order of 100's of MBs.
\end{enumerate}

\begin{table}[htbp]
    \caption{Results for dataset1, topk = 5}
    \label{tab:dataset1}
    \noindent\makebox[\textwidth]{
        \begin{tabular}{|c|c|c|c|c|c|c|}
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 1 Mapper 1 Reducer & 16 & 9 & 8 & 9 & 9  \\
            Reducer time (sec) & 1 Mapper 1 Reducer & 3 & 2 & 2 & 2 & 2   \\
            Total time (sec) & 1 Mapper 1 Reducer & 22 & 15 & 14 & 15 & 14 \\
            \hline
            Fagin Time (sec) & \multicolumn{6}{|c|}{Mapper: 35 Reducer: 8 Total: 58}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 2 Mappers 1 Reducer & 19 & 16 & 8 & 16 & 9  \\
            Reducer time (sec) & 2 Mappers 1 Reducer & 3 & 3 & 2 & 2 & 2   \\
            Total time (sec) & 2 Mappers 1 Reducer & 30 & 22 & 14 & 22 & 14 \\
            \hline
            Fagin Time (sec) & \multicolumn{6}{|c|}{Mapper: 49 Reducer: 9 Total: 72}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 4 Mappers 1 Reducer & 28 & 33 & 8 & 31 & 9  \\
            Reducer time (sec) & 4 Mappers 1 Reducer & 12 & 3 & 2 & 2 & 2   \\
            Total time (sec) & 4 Mappers 1 Reducer & 46 & 40 & 14 & 37 & 14 \\
            \hline
            Fagin Time & \multicolumn{6}{|c|}{Mapper: 81 Reducer: 9 Total: 105}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 1 Mapper 2 Reducers & 15 & 9 & 8 & 9 & 12  \\
            Reducer time (sec) & 1 Mapper 2 Reducers & 6 & 2 & 2 & 3 & 1   \\
            Total time (sec) & 1 Mapper 2 Reducers & 25 & 15 & 15 & 16 & 19 \\
            \hline
            Fagin Time (sec) & \multicolumn{6}{|c|}{Mapper: 38 Reducer: 8 Total: 65}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 2 Mappers 2 Reducers & 19 & 16 & 8 & 16 & 12  \\
            Reducer time (sec) & 2 Mappers 2 Reducers & 8 & 2 & 2 & 2 & 1   \\
            Total time (sec) & 2 Mappers 2 Reducers & 31 & 21 & 14 & 21 & 18 \\
            \hline
            Fagin Time (sec) & \multicolumn{6}{|c|}{Mapper: 52 Reducer: 7 Total: 74}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 4 Mappers 2 Reducers & 27 & 30 & 8 & 31 & 13  \\
            Reducer time (sec) & 4 Mappers 2 Reducers & 12 & 2 & 2 & 2 & 1   \\
            Total time (sec) & 4 Mappers 2 Reducers & 45 & 36 & 14 & 37 & 19 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 81    Reducer: 7  Total: 106}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 1 Mapper 4 Reducers & 15 & 9 & 8 & 10 & 20  \\
            Reducer time (sec) & 1 Mapper 4 Reducers & 4 & 2 & 2 & 2 & 3  \\
            Total time (sec) & 1 Mapper 4 Reducers & 25 & 15 & 14 & 15 & 31 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 47 Reducer: 9 Total: 75}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 2 Mappers 4 Reducers & 19 & 17 & 8 & 16 & 21  \\
            Reducer time (sec) & 2 Mappers 4 Reducers & 7 & 2 & 2 & 2 & 3  \\
            Total time (sec) & 2 Mappers 4 Reducers & 31 & 22 & 14 & 22 & 30 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 62 Reducer: 9 Total: 88}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 4 Mappers 4 Reducers & 26 & 28 & 8 & 32 & 20  \\
            Reducer time (sec) & 4 Mappers 4 Reducers & 12 & 2 & 2 & 2 & 2   \\
            Total time (sec) & 4 Mappers 4 Reducers & 45 & 34 & 14 & 37 & 30 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 88 Reducer: 8 Total: 115}  \\
            \hline
        \end{tabular}
    }
\end{table}


\begin{table}[htbp]
    \caption{Results for dataset2, topk = 5}
    \label{tab:dataset2}
    \noindent\makebox[\textwidth]{
        \begin{tabular}{|c|c|c|c|c|c|c|}
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 1 Mapper 1 Reducer & 41 & 12 & 9 & 12 & 10  \\
            Reducer time (sec) & 1 Mapper 1 Reducer & 6 & 3 & 2 & 2 & 2   \\
            Total time (sec) & 1 Mapper 1 Reducer & 51 & 20 & 15 & 19 & 16 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 43 Reducer: 9 Total: 70}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 2 Mappers 1 Reducer & 43 & 18 & 9 & 19 & 11  \\
            Reducer time (sec) & 2 Mappers 1 Reducer & 8 & 3 & 2 & 2 & 2   \\
            Total time (sec) & 2 Mappers 1 Reducer & 57 & 24 & 15 & 26 & 16 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 57 Reducer: 9 Total: 81}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 4 Mappers 1 Reducer & 50 & 31 & 9 & 32 & 11  \\
            Reducer time (sec) & 4 Mappers 1 Reducer & 15 & 3 & 2 & 2 & 2   \\
            Total time (sec) & 4 Mappers 1 Reducer & 72 & 38 & 15 & 39 & 16 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 83 Reducer: 9 Total: 108}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 1 Mapper 2 Reducers & 41 & 11 & 9 & 12 & 14  \\
            Reducer time (sec) & 1 Mapper 2 Reducers & 6 & 3 & 2 & 2 & 2   \\
            Total time (sec) & 1 Mapper 2 Reducers & 51 & 18 & 15 & 19 & 21 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 46 Reducer: 9 Total: 73}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 2 Mappers 2 Reducers & 42 & 18 & 9 & 19 & 14  \\
            Reducer time (sec) & 2 Mappers 2 Reducers & 8 & 3 & 2 & 3 & 2   \\
            Total time (sec) & 2 Mappers 2 Reducers & 55 & 26 & 15 & 26 & 21 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 60 Reducer: 10 Total: 88}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 4 Mappers 2 Reducers & 50 & 30 & 9 & 32 & 14  \\
            Reducer time (sec) & 4 Mappers 2 Reducers & 16 & 2 & 2 & 2 & 2   \\
            Total time (sec) & 4 Mappers 2 Reducers & 72 & 27 & 15 & 40 & 21 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 85 Reducer: 8 Total: 103}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 1 Mapper 4 Reducers & 39 & 11 & 9 & 13 & 22  \\
            Reducer time (sec) & 1 Mapper 4 Reducers & 5 & 3 & 2 & 2 & 3  \\
            Total time (sec) & 1 Mapper 4 Reducers & 49 & 18 & 15 & 19 & 31 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 55 Reducer: 10 Total: 83}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 2 Mappers 4 Reducers & 43 & 18 & 9 & 19 & 22  \\
            Reducer time (sec) & 2 Mappers 4 Reducers & 9 & 3 & 2 & 2 & 2   \\
            Total time (sec) & 2 Mappers 4 Reducers & 56 & 25 & 15 & 26 & 31 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 68 Reducer: 9 Total: 97}  \\
            \hline
            \hline
             & Configuration & RankSorting & ObjectOccurrence & EndSorting & ScoreCalculation & Filter  \\
            \hline
            Mapper time (sec) & 4 Mappers 4 Reducers & 51 & 32 & 9 & 33 & 22  \\
            Reducer time (sec) & 4 Mappers 4 Reducers & 15 & 2 & 2 & 3 & 2   \\
            Total time (sec) & 4 Mappers 4 Reducers & 72 & 38 & 15 & 39 & 32 \\
            \hline
            Fagin time (sec) & \multicolumn{6}{|c|}{Mapper: 96 Reducer: 9 Total: 115}  \\
            \hline
        \end{tabular}
    }
\end{table}

\section{Conclusions}

In this project we implemented Fagin algorithm using Hadoop MapReduce framework.
We discovered that writing algorithms using MapReduce needs special approach, because of the semantics of this system, otherwise it's easy to end up with very inefficient algorithm.
Although experiments does not show algorithm's scalability this could be explained by the environment which we have used to obtain the results and the datasets which we have used.

\end{document}
